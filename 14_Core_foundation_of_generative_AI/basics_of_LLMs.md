## This file will contain the basic knowledge of LLMs.

_LLMs stands for Large Language Model._

**An LLM is a Model that is trained to 'uderstand', 'process', and 'generate' human language.**

**In order to be generative in nature for any LLM it needs to be trained on large amount of data**

_Transformer is Everything_

**transformer is a model that can:Read input (like text, images, audio) as a sequence of tokens (tiny chunks).Look at the relationships between all tokens at once using something called self-attention.Decide which parts of the input are most important for predicting the output**

_Because this is an iterative process, this LLM needs high computing power! so it requires GPU_
_Computers dont understand human language, they're more comfortable with maths - tokens_
_The character that humans used are mapped to some numbers is called as tokens_
_Every GPT can have its own token mapping in different type_
_Like GPTs Token system could be different, claud's could be different, any so on_
